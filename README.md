# clipcap_rsic

### 1. Dataset Preparation

Before running the code, please ensure that the annotation files and images are prepared and stored according to the following directory structure: 

```md
datasets/
│
├── Sydney_captions/
│   ├── dataset.json
│   └── imgs/
├── UCM_captions/
│   ├── dataset.json
│   └── imgs/
└── RSICD/
    ├── annotations_rsicd/
    │   └── dataset_rsicd.json
    └── RSICD_images/
```

### 2. Generate CLIP embeddings for all images in the dataset

Run the following command to generate the CLIP embeddings:

```bash
python generate_clip_embeddings.py --dataset_type sydney
```

The generated CLIP embeddings will be saved in the `./data` directory.

### 3. Train the model

Specify the dataset using the `--data` parameter (options: sydney, ucm, rsicd, sydney_cn, etc.), and specify the mapping network type using the `--mapping_type` parameter (options: mlp, transformer, or amht).

Example usage:

```bash
python train.py --data sydney --mapping_type mlp
```

During training, the model weights will be saved to the `out_dir` directory specified in the `train.py` file.

### 4. Generate JSON files for evaluation

Run **generate_eval_files.py** to perform RSIC inference on the test set and generate the JSON file for scoring.

```bash
python generate_eval_files.py --model <model_filename>
```

`<model_filename>`: The model weight file generated by **train.py**, such as `sydney_mlp.pt` or `ucm_transformer.pt`.

Example usage:

```bash
python generate_eval_files.py --model sydney_mlp.pt
```

The generated JSON file (for scoring evaluation) will contain image IDs and their corresponding generated descriptions. The output file will be automatically saved in the `./output/eval_files/` directory, with the filename `<model_filename>.json`.

### 5. Evaluating image captioning results

**scores.py** will automatically detect the dataset name from the filename and compare it with the corresponding ground-truth annotations for scoring.

```bash
python scores.py --eval_file sydney_mlp.json
```

The evaluation results will be saved in the `./output/scores` directory.